nextflow_workflow {

    name "Test Subworkflow PREPROCESS_RNASEQ"
    script "../main.nf"
    workflow "PREPROCESS_RNASEQ"
    config "./nextflow.config"

    tag "subworkflows"
    tag "subworkflows_nfcore"
    tag "subworkflows/preprocess_rnaseq"

    tag "bbmap/bbsplit"
    tag "cat"
    tag "cat/fastq"
    tag "fastqc"
    tag "sortmerna"
    tag "subworkflows/fastq_fastqc_umitools_trimgalore"
    tag "subworkflows/fastq_fastqc_umitools_fastp"
    tag "subworkflows/fastq_subsample_fq_salmon"

    test("homo_sapiens paired-end [fastq] fastp") {

        when {
            workflow {
                """
                input[0] = Channel.of([ [ id:'test', single_end:false, strandedness:'auto' ], // meta map
                        [file(params.test_data['homo_sapiens']['illumina']['test_1_fastq_gz'], checkIfExists: true),
                        file(params.test_data['homo_sapiens']['illumina']['test_2_fastq_gz'], checkIfExists: true)
                        ]]) // ch_reads
                input[1] = Channel.of(file(params.test_data['homo_sapiens']['genome']['genome_fasta'], checkIfExists: true)) // ch_fasta
                input[2] = Channel.of(file(params.test_data['homo_sapiens']['genome']['transcriptome_fasta'], checkIfExists: true)) // ch_transcript_fasta
                input[3] = Channel.of(file(params.test_data['homo_sapiens']['genome']['genome_gtf'], checkIfExists: true)) // ch_gtf
                input[4] = []              // ch_salmon_index
                input[5] = []              // ch_bbsplit_index
                input[6] = []              // ch_ribo_db
                input[7] = true            // skip_bbsplit
                input[8] = false           // skip_fastqc
                input[9] = false           // skip_trimming
                input[10] = true           // skip_umi_extract
                input[11] = true           // make_salmon_index
                input[12] = 'fastp'        // trimmer
                input[13] = 10             // min_trimmed_reads
                input[14] = true           // save_trimmed
                input[15] = false          // remove_ribo_rna
                input[16] = false          // with_umi
                input[17] = 0              // umi_discard_read
                """
            }
        }

        then {
            def pelines1 = path(workflow.out.reads[0][1][0]).linesGzip
            def pelines2 = path(workflow.out.reads[0][1][1]).linesGzip
            assertAll(
                { assert workflow.success},
                { assert snapshot(pelines1).md5().match("fastp_test_pe_reads_1_lines") },
                { assert snapshot(pelines1.size()).match("fastp_test_pe_reads_1_size") },
                { assert snapshot(pelines2).md5().match("fastp_test_pe_reads_2_lines") },
                { assert snapshot(pelines2.size()).match("fastp_test_pe_reads_2_size") },
                { assert snapshot(workflow.out.trim_read_count).match("fastp_read_count") }
                // This doesn't work- 'cat' changes between Conda and Docker -
                // leaving it here until we find a way to address that
                // { assert snapshot(workflow.out.versions).match("fastp_versions") }
            )
        }
    }
    test("homo_sapiens paired-end [fastq] trimgalore") {

        when {
            workflow {
                """
                input[0] = Channel.of([ [ id:'test', single_end:false, strandedness:'auto' ], // meta map
                        [file(params.test_data['homo_sapiens']['illumina']['test_1_fastq_gz'], checkIfExists: true),
                        file(params.test_data['homo_sapiens']['illumina']['test_2_fastq_gz'], checkIfExists: true)
                        ]]) // ch_reads
                input[1] = Channel.of(file(params.test_data['homo_sapiens']['genome']['genome_fasta'], checkIfExists: true)) // ch_fasta
                input[2] = Channel.of(file(params.test_data['homo_sapiens']['genome']['transcriptome_fasta'], checkIfExists: true)) // ch_transcript_fasta
                input[3] = Channel.of(file(params.test_data['homo_sapiens']['genome']['genome_gtf'], checkIfExists: true)) // ch_gtf
                input[4] = []              // ch_salmon_index
                input[5] = []              // ch_bbsplit_index
                input[6] = []              // ch_ribo_db
                input[7] = true            // skip_bbsplit
                input[8] = false           // skip_fastqc
                input[9] = false           // skip_trimming
                input[10] = true           // skip_umi_extract
                input[11] = true           // make_salmon_index
                input[12] = 'fastp'        // trimmer
                input[13] = 10             // min_trimmed_reads
                input[14] = true           // save_trimmed
                input[15] = false          // remove_ribo_rna
                input[16] = false          // with_umi
                input[17] = 0              // umi_discard_read
                """
            }
        }

        then {
            def pelines1 = path(workflow.out.reads[0][1][0]).linesGzip
            def pelines2 = path(workflow.out.reads[0][1][1]).linesGzip
            assertAll(
                { assert workflow.success},
                { assert snapshot(pelines1).md5().match("trimgalore_test_pe_reads_1_lines") },
                { assert snapshot(pelines1.size()).match("trimgalore_test_pe_reads_1_size") },
                { assert snapshot(pelines2).md5().match("trimgalore_test_pe_reads_2_lines") },
                { assert snapshot(pelines2.size()).match("trimgalore_test_pe_reads_2_size") },
                { assert snapshot(workflow.out.trim_read_count).match("trimgalore_read_count") }
                // This doesn't work- 'cat' changes between Conda and Docker -
                // leaving it here until we find a way to address that
                //{ assert snapshot(workflow.out.versions).match("trimgalore_versions") }
            )
        }
    }
}
