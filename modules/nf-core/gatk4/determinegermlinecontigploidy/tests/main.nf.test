nextflow_process {

    name "Test Process GATK4_DETERMINEGERMLINECONTIGPLOIDY"
    script "../main.nf"
    config "./nextflow.config"
    process "GATK4_DETERMINEGERMLINECONTIGPLOIDY"

    tag "modules"
    tag "modules_nfcore"
    tag "gatk4"
    tag "gatk4/collectreadcounts"
    tag "gatk4/determinegermlinecontigploidy"

    setup {
        run("GATK4_COLLECTREADCOUNTS") {
            script "../../collectreadcounts/main.nf"
            process {
                """
                bed = Channel.of(file(params.modules_testdata_base_path + 'genomics/homo_sapiens/genome/genome.multi_intervals.bed', checkIfExists: true))

                ch_input = Channel.of([
                    [ id:'test', single_end:false ], // meta map
                    file(params.modules_testdata_base_path + "genomics/homo_sapiens/illumina/bam/test.paired_end.sorted.bam", checkIfExists: true),
                    file(params.modules_testdata_base_path + "genomics/homo_sapiens/illumina/bam/test.paired_end.sorted.bam.bai", checkIfExists: true)
                ],
                [
                    [ id:'test2', single_end:false ], // meta map
                    file(params.modules_testdata_base_path + "genomics/homo_sapiens/illumina/bam/test2.paired_end.sorted.bam", checkIfExists: true),
                    file(params.modules_testdata_base_path + "genomics/homo_sapiens/illumina/bam/test2.paired_end.sorted.bam.bai", checkIfExists: true)
                ],
                ).combine(bed)

                ch_fasta = Channel.of([ [ id:'test' ], file(params.modules_testdata_base_path + "genomics/homo_sapiens/genome/genome.fasta", checkIfExists: true)]).collect()
                ch_fai   = Channel.of([ [ id:'test' ], file(params.modules_testdata_base_path + "genomics/homo_sapiens/genome/genome.fasta.fai", checkIfExists: true)]).collect()
                ch_dict  = Channel.of([ [ id:'test' ], file(params.modules_testdata_base_path + "genomics/homo_sapiens/genome/genome.dict", checkIfExists: true)]).collect()

                input = [ch_input, ch_fasta, ch_fai, ch_dict]
                """
            }
        }
    }

    test("homo sapiens - bam") {

        when {
            process {
                """
                contig_ploidy_table = file(params.modules_testdata_base_path + "genomics/homo_sapiens/illumina/gatk/contig_ploidy_priors_table.tsv", checkIfExists: true)
                bed = Channel.of(file(params.modules_testdata_base_path + 'genomics/homo_sapiens/genome/genome.multi_intervals.bed', checkIfExists: true))

                input[0] = GATK4_COLLECTREADCOUNTS.out.tsv
                    .map({ meta, tsv -> [[id:'test'] , tsv ] })
                    .groupTuple()
                    .combine(bed)
                    .map({ meta, counts, bed -> [ meta, counts, bed, [] ]})
                input[1] = [[],[]]
                input[2] = contig_ploidy_table
                """
            }
        }

        then {
            assertAll(
                { assert process.success },
                { assert snapshot(
                    process.out.versions,
                    file(process.out.calls[0][1]).list().sort().collect { path -> file(path).name },
                    file(process.out.model[0][1]).list().sort().collect { path -> file(path).name },
                ).match() }
            )
        }

    }

    test("homo sapiens - bam - stub") {

        options "-stub"

        when {
            process {
                """
                contig_ploidy_table = file(params.modules_testdata_base_path + "genomics/homo_sapiens/illumina/gatk/contig_ploidy_priors_table.tsv", checkIfExists: true)
                bed = Channel.of(file(params.modules_testdata_base_path + 'genomics/homo_sapiens/genome/genome.multi_intervals.bed', checkIfExists: true))

                input[0] = GATK4_COLLECTREADCOUNTS.out.tsv
                    .map({ meta, tsv -> [[id:'test'] , tsv ] })
                    .groupTuple()
                    .combine(bed)
                    .map({ meta, counts, bed -> [ meta, counts, bed, [] ]})
                input[1] = [[],[]]
                input[2] = contig_ploidy_table
                """
            }
        }

        then {
            assertAll(
                { assert process.success },
                { assert snapshot(process.out).match() }
            )
        }

    }

}
